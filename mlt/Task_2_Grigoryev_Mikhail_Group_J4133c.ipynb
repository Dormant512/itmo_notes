{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a136af",
   "metadata": {},
   "source": [
    "# MLT Lab 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ead062bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/dormant/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/dormant/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/dormant/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import TreebankWordTokenizer, WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfa641",
   "metadata": {},
   "source": [
    "## Task 1: most common words in chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33127301",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./alice.txt') as f:\n",
    "    l = f.readlines()\n",
    "    \n",
    "l = [item for item in l if item != '\\n']\n",
    "    \n",
    "splitter = ['CHAPTER I.\\n', 'CHAPTER II.\\n', 'CHAPTER III.\\n',\n",
    "            'CHAPTER IV.\\n', 'CHAPTER V.\\n', 'CHAPTER VI.\\n',\n",
    "            'CHAPTER VII.\\n', 'CHAPTER VIII.\\n', 'CHAPTER IX.\\n',\n",
    "            'CHAPTER X.\\n', 'CHAPTER XI.\\n', 'CHAPTER XII.\\n',\n",
    "            '*** END OF THE PROJECT GUTENBERG EBOOK ALICE’S ADVENTURES IN WONDERLAND ***\\n']\n",
    "splitter_idx = [l.index(item) for item in splitter]\n",
    "\n",
    "alice = [0] * (len(splitter) - 1)\n",
    "\n",
    "for i in range(len(splitter)-1):\n",
    "    alice[i] = l[splitter_idx[i]:splitter_idx[i+1]]\n",
    "\n",
    "alice = [\" \".join(item) for item in alice]\n",
    "alice = [re.sub(r\"[‘’.*?,!“”—;()]\", \" \", item) for item in alice]\n",
    "alice = [re.sub(\"\\n|_\", \" \", item) for item in alice]\n",
    "alice = [re.sub(\" +\", \" \", item) for item in alice]\n",
    "alice = [item.strip() for item in alice]\n",
    "\n",
    "# Tokenization\n",
    "alice = [item.lower() for item in alice]\n",
    "alice = [item.split(\" \") for item in alice]\n",
    "\n",
    "# Stop-words and lemmatization\n",
    "stop_words = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(alice)):\n",
    "    alice[i] = [item for item in alice[i] if item not in stop_words]\n",
    "    alice[i] = [lemmatizer.lemmatize(item) for item in alice[i]]\n",
    "    \n",
    "alice = [\" \".join(item).strip() for item in alice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2d3aa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chapter xii alice evidence cried alice quite forgetting flurry moment large grown last minute jumped hurry tipped jury-box edge skirt upsetting juryman head crowd lay sprawling reminding much globe goldfish accidentally upset week oh beg pardon exclaimed tone great dismay began picking quickly could accident goldfish kept running head vague sort idea must collected put back jury-box would die trial cannot proceed said king grave voice juryman back proper place repeated great emphasis looking hard alice said alice looked jury-box saw haste put lizard head downwards poor little thing waving tail melancholy way quite unable move soon got put right signifies much said think would quite much use trial one way soon jury little recovered shock upset slate pencil found handed back set work diligently write history accident except lizard seemed much overcome anything sit mouth open gazing roof court know business king said alice nothing said alice nothing whatever persisted king nothing whatever said alice important king said turning jury beginning write slate white rabbit interrupted: un important majesty mean course said respectful tone frowning making face spoke un important course meant king hastily said went undertone important unimportant unimportant important trying word sounded best jury wrote important unimportant alice could see near enough look slate matter bit thought moment king time busily writing note-book cackled silence read book rule forty-two person mile high leave court everybody looked alice mile high said alice said king nearly two mile high added queen well go rate said alice: besides regular rule: invented oldest rule book said king ought number one said alice king turned pale shut note-book hastily consider verdict said jury low trembling voice evidence come yet please majesty said white rabbit jumping great hurry paper picked said queen opened yet said white rabbit seems letter written prisoner somebody must said king unless written nobody usual know directed said one juryman directed said white rabbit fact nothing written outside unfolded paper spoke added letter all: set verse prisoner handwriting asked another juryman said white rabbit queerest thing jury looked puzzled must imitated somebody else hand said king jury brightened please majesty said knave write prove did: name signed end sign said king make matter worse must meant mischief else signed name like honest man general clapping hand this: first really clever thing king said day prof guilt said queen prof nothing sort said alice even know read said king white rabbit put spectacle shall begin please majesty asked begin beginning king said gravely go till come end: stop verse white rabbit read: told mentioned him: gave good character said could swim sent word gone know true : push matter would become gave one gave two gave u three returned though mine chance involved affair trust set free exactly notion fit obstacle came let know liked best must ever secret kept rest important piece evidence heard yet said king rubbing hand let jury one explain said alice grown large last minute bit afraid interrupting give sixpence believe atom meaning jury wrote slate believe atom meaning none attempted explain paper meaning said king save world trouble know try find yet know went spreading verse knee looking one eye seem see meaning said could swim swim added turning knave knave shook head sadly look like said certainly made entirely cardboard right far said king went muttering verse himself: know true jury course gave one gave two must tart know go returned said alice said king triumphantly pointing tart table nothing clearer fit never fit dear think said queen never said queen furiously throwing inkstand lizard spoke unfortunate little bill left writing slate one finger found made mark hastily began using ink trickling face long lasted word fit said king looking round court smile dead silence pun king added offended tone everybody laughed let jury consider verdict king said twentieth time day said queen sentence first verdict afterwards stuff nonsense said alice loudly idea sentence first hold tongue said queen turning purple said alice head queen shouted top voice nobody moved care said alice grown full size time nothing pack card whole pack rose air came flying upon her: gave little scream half fright half anger tried beat found lying bank head lap sister gently brushing away dead leaf fluttered tree upon face wake alice dear said sister long sleep oh curious dream said alice told sister well could remember strange adventure reading finished sister kissed said curious dream dear certainly: run tea getting late alice got ran thinking ran well might wonderful dream sister sat still left leaning head hand watching setting sun thinking little alice wonderful adventure till began dreaming fashion dream: first dreamed little alice tiny hand clasped upon knee bright eager eye looking could hear tone voice see queer little toss head keep back wandering hair would always get eye still listened seemed listen whole place around became alive strange creature little sister dream long grass rustled foot white rabbit hurried frightened mouse splashed way neighbouring pool could hear rattle teacup march hare friend shared never-ending meal shrill voice queen ordering unfortunate guest execution pig-baby sneezing duchess knee plate dish crashed around shriek gryphon squeaking lizard slate-pencil choking suppressed guinea-pigs filled air mixed distant sob miserable mock turtle sat closed eye half believed wonderland though knew open would change dull reality grass would rustling wind pool rippling waving reed rattling teacup would change tinkling sheep-bells queen shrill cry voice shepherd boy sneeze baby shriek gryphon queer noise would change knew confused clamour busy farm-yard lowing cattle distance would take place mock turtle heavy sob lastly pictured little sister would after-time grown woman would keep riper year simple loving heart childhood: would gather little child make eye bright eager many strange tale perhaps even dream wonderland long ago: would feel simple sorrow find pleasure simple joy remembering child-life happy summer day end'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c8715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_bow = CountVectorizer()\n",
    "vect_bow.fit(alice)\n",
    "\n",
    "simple_train_dtm = vect_bow.transform(alice)\n",
    "df = pd.DataFrame(simple_train_dtm.toarray(), columns=vect_bow.get_feature_names_out()).T\n",
    "df = df.drop(['alice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2793f7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abide</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absence</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absurd</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceptance</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0   1   2   3   4   5   6   7   8   9   10  11\n",
       "abide        0   0   0   0   0   1   0   0   0   0   0   0\n",
       "able         0   1   0   0   0   0   0   0   0   0   0   0\n",
       "absence      0   0   0   0   0   0   0   0   1   0   0   0\n",
       "absurd       0   0   1   0   0   1   0   0   0   0   0   0\n",
       "acceptance   0   0   1   0   0   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdbb269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten = [df[col].nlargest(10).index.values for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c30c37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER I\n",
      "little, way, like, think, see, door, one, rabbit, time, could\n",
      "\n",
      "CHAPTER II\n",
      "mouse, little, oh, said, dear, go, thing, foot, like, must\n",
      "\n",
      "CHAPTER III\n",
      "said, mouse, dodo, know, one, soon, bird, course, dry, long\n",
      "\n",
      "CHAPTER IV\n",
      "little, rabbit, one, bill, said, get, heard, sure, thought, voice\n",
      "\n",
      "CHAPTER V\n",
      "said, caterpillar, pigeon, serpent, little, well, know, minute, one, size\n",
      "\n",
      "CHAPTER VI\n",
      "said, cat, like, footman, duchess, little, baby, mad, much, know\n",
      "\n",
      "CHAPTER VII\n",
      "said, hatter, dormouse, march, hare, time, well, know, thing, tea\n",
      "\n",
      "CHAPTER VIII\n",
      "said, queen, head, king, cat, three, hedgehog, like, one, went\n",
      "\n",
      "CHAPTER IX\n",
      "said, turtle, mock, gryphon, duchess, queen, went, never, little, say\n",
      "\n",
      "CHAPTER X\n",
      "said, gryphon, turtle, mock, would, lobster, dance, soup, beautiful, voice\n",
      "\n",
      "CHAPTER XI\n",
      "said, king, hatter, court, dormouse, one, witness, queen, began, rabbit\n",
      "\n",
      "CHAPTER XII\n",
      "said, king, jury, would, little, queen, know, head, one, rabbit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num, item in enumerate(top_ten):\n",
    "    print(splitter[num][:-2])\n",
    "    print(\", \".join(item))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a2c04",
   "metadata": {},
   "source": [
    "## Task 2: most common verbs in sentences with Alice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0de73fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beginning', 'get', 'tired', 'sitting', 'say', 'occurred', 'wondered', 'seemed', 'took', 'looked', 'hurried', 'started', 'flashed', 'seen', 'take', 'see', 'went', 'considering', 'get', 'went', 'stopping', 'falling', 'tumbling', 'let', 'see', 'showing', 'say', 'got', 'say', 'began', 'talking', 'began', 'get', 'went', 'saying', 'looked', 'hurrying', 'went', 'say', 'turned', 'getting', 'locked', 'trying', 'walked', 'wondering', 'get', 'came', 'made', 'opened', 'led', 'looked', 'longed', 'get', 'get', 'go', 'see', 'happened', 'begun', 'seemed', 'waiting', 'went', 'hoping', 'find', 'shutting', 'said', 'printed', 'say', 'going', 'ventured', 'finding', 'buttered', 'finished', 'said', 'shutting', 'waited', 'see', 'going', 'know', 'said', 'going', 'finding', 'happened', 'decided', 'going', 'said', 'leave', 'said', 'make', 'make', 'get', 'holding', 'growing', 'find', 'remained', 'got', 'expecting', 'happen', 'seemed', 'go', 'cried', 'go', 'ashamed', 'said', 'say', 'go', 'came', 'began', 'started', 'dropped', 'skurried', 'go', 'took', 'fanning', 'went', 'said', 'filled', 'went', 'go', 'cried', 'said', 'frightened', 'find', 'come', 'go', 'find', 'digging', 'lodging', 'said', 'trying', 'find', 'speaking', 'done', 'remembered', 'seen', 'come', 'happened', 'cried', 'feeling', 'said', 'soothing', 'went', 'purring', 'licking', 'washing', 'catching', 'cried', 'offended', 'said', 'went', 'cried', 'offended', 'turned', 'said', 'trembling', 'let', 'get', 'led', 'get', 'seemed', 'find', 'talking', 'known', 'turned', 'say', 'know', 'allow', 'knowing', 'refused', 'said', 'fixed', 'get', 'turning', 'said', 'said', 'wanted', 'know', 'paused', 'seemed', 'say', 'said', 'pointing', 'crowded', 'calling', 'confused', 'pulled', 'got', 'handed', 'went', 'turning', 'said', 'looked', 'say', 'bowed', 'took', 'looking', 'promised', 'know', 'said', 'added', 'offended', 'said', 'turning', 'sighing', 'said', 'looking', 'said', 'said', 'got', 'said', 'make', 'looking', 'pleaded', 'called', 'joined', 'said', 'addressing', 'replied', 'moved', 'began', 'guessed', 'looking', 'began', 'hunting', 'seen', 'seemed', 'changed', 'noticed', 'went', 'hunting', 'called', 'frightened', 'pointed', 'trying', 'made', 'seems', 'said', 'going', 'began', 'fancying', 'went', 'let', 'began', 'ordering', 'grew', 'seemed', 'getting', 'growing', 'ordered', 'get', 'coming', 'trembled', 'forgetting', 'came', 'tried', 'opened', 'pressed', 'proved', 'say', 'go', 'get', 'waiting', 'fancied', 'made', 'said', 'came', 'squeaking', 'know', 'flustered', 'know', 'come', 'go', 'said', 'called', 'began', 'moving', 'say', 'came', 'rattling', 'noticed', 'turning', 'came', 'made', 'appeared', 'got', 'said', 'wandered', 'find', 'said', 'coaxing', 'tried', 'frightened', 'coaxing', 'knowing', 'rushed', 'made', 'believe', 'dodged', 'keep', 'run', 'appeared', 'made', 'tumbled', 'get', 'thinking', 'expecting', 'trampled', 'began', 'running', 'panting', 'hanging', 'seemed', 'making', 'tired', 'sounded', 'said', 'fanned', 'liked', 'teaching', 'looked', 'see', 'looked', 'looked', 'took', 'addressed', 'replied', 'know', 'know', 'got', 'changed', 'said', 'see', 'replied', 'confusing', 'said', 'know', 'feeling', 'said', 'know', 'making', 'said', 'puzzling', 'seemed', 'turned', 'sounded', 'turned', 'came', 'said', 'swallowing', 'said', 'remember', 'used', 'keep', 'replied', 'folded', 'said', 'said', 'got', 'altered', 'replied', 'changing', 'know', 'said', 'contradicted', 'losing', 'said', 'wretched', 'pleaded', 'waited', 'remained', 'looking', 'trying', 'make', 'said', 'changed', 'see', 'looked', 'seemed', 'said', 'said', 'talking', 'said', 'puzzled', 'saying', 'finished', 'said', 'beginning', 'see', 'said', 'said', 'remembered', 'gone', 'tasted', 'said', 'know', 'gave', 'adding', 'looking', 'know', 'said', 'looking', 'crouched', 'getting', 'entangled', 'come', 'opened', 'noticed', 'powdered', 'curled', 'laughed', 'run', 'gone', 'sitting', 'staring', 'went', 'knocked', 'said', 'get', 'looking', 'speaking', 'asked', 'said', 'talking', 'said', 'said', 'sneezing', 'said', 'said', 'addressed', 'took', 'went', 'know', 'grinned', 'know', 'know', 'said', 'feeling', 'got', 'cried', 'said', 'get', 'showing', 'glanced', 'see', 'take', 'stirring', 'seemed', 'listening', 'went', 'tossing', 'howled', 'said', 'flinging', 'take', 'leave', 'said', 'expressing', 'grunted', 'looked', 'see', 'getting', 'going', 'said', 'beginning', 'get', 'grinned', 'come', 'went', 'said', 'get', 'added', 'denied', 'tried', 'go', 'remarked', 'said', 'proved', 'went', 'know', 'said', 'purring', 'growling', 'said', 'said', 'invited', 'getting', 'used', 'happening', 'turned', 'said', 'come', 'waited', 'expecting', 'see', 'appear', 'walked', 'said', 'said', 'replied', 'keep', 'appearing', 'vanishing', 'make', 'seen', 'cried', 'coming', 'said', 'looked', 'said', 'know', 'said', 'looking', 'make', 'said', 'said', 'replied', 'say', 'know', 'said', 'dropped', 'remember', 'said', 'turning', 'taken', 'looking', 'shaking', 'holding', 'considered', 'said', 'looking', 'replied', 'puzzled', 'said', 'turning', 'give', 'sighed', 'know', 'said', 'know', 'said', 'know', 'asked', 'said', 'exclaimed', 'came', 'said', 'ventured', 'know', 'said', 'pleaded', 'said', 'took', 'eating', 'done', 'know', 'remarked', 'tried', 'puzzled', 'went', 'take', 'said', 'replied', 'offended', 'take', 'asked', 'said', 'know', 'say', 'helped', 'turned', 'repeated', 'beginning', 'went', 'said', 'said', 'forgetting', 'moved', 'followed', 'moved', 'took', 'got', 'began', 'said', 'choosing', 'confused', 'let', 'go', 'interrupting', 'said', 'said', 'confused', 'said', 'got', 'walked', 'fell', 'took', 'going', 'looked', 'hoping', 'trying', 'said', 'went', 'came', 'say', 'begun', 'chanced', 'watching', 'looked', 'bowed', 'said', 'rose', 'looked', 'see', 'came', 'recognised', 'talking', 'hurried', 'smiling', 'said', 'went', 'noticing', 'remember', 'see', 'came', 'stopped', 'looked', 'said', 'said', 'tossing', 'turning', 'went', 'said', 'added', 'said', 'said', 'moved', 'remaining', 'said', 'looked', 'shouted', 'roared', 'joined', 'wondering', 'happen', 'said', 'said', 'said', 'gave', 'seen', 'make', 'managing', 'succeeded', 'getting', 'hanging', 'got', 'straightened', 'going', 'give', 'puzzled', 'got', 'going', 'provoking', 'find', 'crawling', 'wanted', 'getting', 'walking', 'came', 'began', 'happen', 'waited', 'appeared', 'nodded', 'appeared', 'began', 'feeling', 'began', 'complaining', 'confusing', 'got', 'go', 'walking', 'croqueted', 'coming', 'said', 'noticed', 'went', 'finishing', 'said', 'going', 'looking', 'said', 'allow', 'got', 'said', 'go', 'see', 'going', 'screaming', 'engaged', 'seemed', 'croqueting', 'gone', 'see', 'trying', 'gone', 'appeared', 'appealed', 'settle', 'repeated', 'make', 'said', 'say', 'said', 'walked', 'find', 'made', 'ventured', 'squeezed', 'keeping', 'said', 'whispered', 'done', 'minding', 'said', 'digging', 'added', 'take', 'take', 'replied', 'feeling', 'tried', 'remarked', 'said', 'said', 'seemed', 'said', 'exclaimed', 'attended', 'said', 'written', 'follow', 'say', 'say', 'said', 'said', 'beginning', 'said', 'died', 'linked', 'began', 'looked', 'folded', 'frowning', 'let', 'go', 'said', 'frightened', 'say', 'followed', 'sentenced', 'taken', 'leave', 'said', 'seen', 'said', 'said', 'come', 'said', 'walked', 'say', 'pardoned', 'go', 'see', 'ordered', 'walked', 'leaving', 'go', 'waited', 'said', 'said', 'went', 'ordered', 'gone', 'sitting', 'came', 'sighing', 'see', 'getting', 'saying', 'interesting', 'thinking', 'come', 'said', 'asked', 'ashamed', 'asking', 'added', 'looked', 'interrupted', 'added', 'went', 'said', 'said', 'learned', 'said', 'wanted', 'said', 'inquired', 'ventured', 'say', 'said', 'make', 'encouraged', 'turned', 'said', 'said', 'said', 'exclaimed', 'made', 'went', 'looked', 'tried', 'recovered', 'running', 'went', 'lived', 'said', 'introduced', 'began', 'say', 'tasted', 'said', 'said', 'said', 'dropping', 'looked', 'said', 'said', 'began', 'dancing', 'treading', 'passed', 'waving', 'interesting', 'said', 'feeling', 'whiting', 'said', 'seen', 'believe', 'replied', 'said', 'interesting', 'said', 'puzzled', 'looked', 'considered', 'gave', 'asked', 'whiting', 'said', 'running', 'said', 'keep', 'said', 'said', 'beginning', 'said', 'going', 'began', 'telling', 'looked', 'said', 'wondering', 'happen', 'said', 'puzzled', 'longed', 'come', 'went', 'trembling', 'passed', 'sharing', 'follows', 'took', 'leave', 'said', 'replied', 'said', 'offended', 'cried', 'taking', 'hurried', 'waiting', 'panted', 'answered', 'come', 'looked', 'made', 'get', 'done', 'find', 'obliged', 'say', 'see', 'whispered', 'began', 'stopped', 'cried', 'see', 'looking', 'writing', 'went', 'got', 'taking', 'puzzled', 'made', 'beginning', 'get', 'leave', 'decided', 'said', 'growing', 'said', 'know', 'growing', 'seen', 'done', 'carried', 'guessed', 'got', 'began', 'sneezing', 'watched', 'fumbled', 'feeling', 'see', 'got', 'said', 'cried', 'forgetting', 'upsetting', 'sprawling', 'reminding', 'said', 'repeated', 'looking', 'said', 'looked', 'waving', 'said', 'said', 'said', 'see', 'looked', 'said', 'go', 'said', 'invented', 'said', 'said', 'said', 'rubbing', 'let', 'said', 'interrupting', 'give', 'said', 'went', 'muttering', 'know', 'gave', 'gave', 'know', 'go', 'returned', 'said', 'said', 'said', 'said', 'said', 'remember', 'finished', 'kissed', 'said', 'run', 'getting', 'got', 'thinking', 'leaning', 'watching', 'setting', 'thinking', 'began', 'dreaming', 'dreamed', 'looking', 'see', 'keep', 'wandering', 'get', 'listened', 'seemed', 'became']\n"
     ]
    }
   ],
   "source": [
    "alice = [0] * (len(splitter) - 1)\n",
    "\n",
    "for i in range(len(splitter)-1):\n",
    "    alice[i] = \" \".join(l[splitter_idx[i]+2:splitter_idx[i+1]])\n",
    "\n",
    "alice = re.split(r'[.!?]', \" \".join(alice))\n",
    "alice = [re.sub(r\"[‘’*,“”—;()]\", \" \", item) for item in alice]\n",
    "alice = [re.sub(\"\\n|_\", \" \", item) for item in alice]\n",
    "alice = [re.sub(\" +\", \" \", item) for item in alice]\n",
    "alice = [item.strip() for item in alice]\n",
    "\n",
    "# Tokenization\n",
    "alice = [item.lower() for item in alice]\n",
    "alice = [item.split(\" \") for item in alice]\n",
    "\n",
    "# Stop-words and lemmatization\n",
    "stop_words = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(alice)):\n",
    "    alice[i] = [item for item in alice[i] if item not in stop_words]\n",
    "    alice[i] = [lemmatizer.lemmatize(item) for item in alice[i]]\n",
    "\n",
    "# Sentences, that contain Alice\n",
    "alice = [\" \".join(item).strip() for item in alice]\n",
    "alice = [item for item in alice if \"alice\" in item]\n",
    "\n",
    "# Verbs in those sentences\n",
    "for i in range(len(alice)):\n",
    "    alice[i] = [item for item in alice[i].split(\" \") if 'VB' in nltk.pos_tag([item])[0][1]]\n",
    "\n",
    "alice = [\" \".join(item).strip() for item in alice if len(item)>0]\n",
    "alice = \" \".join(alice).split(\" \")\n",
    "print(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b2e105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common verbs in sentences with Alice:\n",
      "\tsaid\t174\n",
      "\twent\t30\n",
      "\tknow\t28\n",
      "\tlooked\t24\n",
      "\tsay\t22\n",
      "\tsee\t22\n",
      "\tget\t20\n",
      "\tbegan\t20\n",
      "\tgot\t18\n",
      "\tgo\t18\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter(alice)\n",
    "print(\"Most common verbs in sentences with Alice:\")\n",
    "for i in counter.most_common(10):\n",
    "    print(f\"\\t{i[0]}\\t{i[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87c08c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common verb stems in sentences with Alice:\n",
      "\tsaid\t174\n",
      "\tlook\t39\n",
      "\twent\t30\n",
      "\tgo\t30\n",
      "\tknow\t30\n",
      "\tget\t29\n",
      "\tsay\t25\n",
      "\tsee\t22\n",
      "\tbegan\t20\n",
      "\tgot\t18\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer(language='english')\n",
    "\n",
    "# if we stem verbs, we get:\n",
    "alice = [snowball.stem(item) for item in alice]\n",
    "counter = collections.Counter(alice)\n",
    "print(\"Most common verb stems in sentences with Alice:\")\n",
    "for i in counter.most_common(10):\n",
    "    print(f\"\\t{i[0]}\\t{i[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
